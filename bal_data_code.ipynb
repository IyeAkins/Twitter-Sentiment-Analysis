{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout, Input, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import re\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed CSV data\n",
    "tweet_data = pd.read_csv(r'tweets.csv')  # Update with your data path\n",
    "emoji_scores_data = pd.read_csv(r'Emoji-Sentiment-Data-v1.0.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select positive and negative rows\n",
    "positive_rows = tweet_data[tweet_data['Response'] == 'positive']\n",
    "negative_rows = tweet_data[tweet_data['Response'] == 'negative']\n",
    "\n",
    "# Select a random sample of 1500 neutral rows\n",
    "neutral_rows = tweet_data[tweet_data['Response'] == 'neutral'].sample(n=2000, random_state=1)  # You can change the random_state if desired\n",
    "\n",
    "# Combine the selected rows into a new DataFrame\n",
    "tweet_data = pd.concat([positive_rows, negative_rows, neutral_rows])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Username</th>\n",
       "      <th>Content</th>\n",
       "      <th>No of likes</th>\n",
       "      <th>No of Retweets</th>\n",
       "      <th>No of Replies</th>\n",
       "      <th>No of quoteCount</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.340000e+18</td>\n",
       "      <td>Bulama8976</td>\n",
       "      <td>HumilityEmpathyCourageVisionResilience and Acc...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30/12/2020</td>\n",
       "      <td>23:51:09</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.340000e+18</td>\n",
       "      <td>malaminuu</td>\n",
       "      <td>The Statecritical policy priority is to build ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30/12/2020</td>\n",
       "      <td>23:43:47</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.340000e+18</td>\n",
       "      <td>busuyikk</td>\n",
       "      <td>AtikuSaraki and Kwankwanso may have been forgi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30/12/2020</td>\n",
       "      <td>23:40:53</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1.340000e+18</td>\n",
       "      <td>aesha_m_dawood</td>\n",
       "      <td>Thank you üôèüèæüòä</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30/12/2020</td>\n",
       "      <td>23:35:47</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1.340000e+18</td>\n",
       "      <td>AbbanHajiya7</td>\n",
       "      <td>Atiku Support Organization Aso   Aso to asorock</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30/12/2020</td>\n",
       "      <td>23:18:55</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4441</th>\n",
       "      <td>4445</td>\n",
       "      <td>1.340000e+18</td>\n",
       "      <td>MOyewola</td>\n",
       "      <td>rydayI am a Muslim but I donbelieve in Hell fi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30/12/2020</td>\n",
       "      <td>19:25:28</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8323</th>\n",
       "      <td>8327</td>\n",
       "      <td>1.330000e+18</td>\n",
       "      <td>nabrga</td>\n",
       "      <td>Bros u can go ahead n block me na ur phone n d...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22/11/2020</td>\n",
       "      <td>21:16:43</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11372</th>\n",
       "      <td>11376</td>\n",
       "      <td>1.340000e+18</td>\n",
       "      <td>BonaNaija</td>\n",
       "      <td>You must contest in 2023 presidential election...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30/12/2020</td>\n",
       "      <td>9:56:47</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9340</th>\n",
       "      <td>9344</td>\n",
       "      <td>1.340000e+18</td>\n",
       "      <td>Chude</td>\n",
       "      <td>I said it when Funke did Your Excellencythat t...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30/12/2020</td>\n",
       "      <td>18:28:52</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7084</th>\n",
       "      <td>7088</td>\n",
       "      <td>1.340000e+18</td>\n",
       "      <td>_SecretSinner</td>\n",
       "      <td>You do tho Jonathan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30/12/2020</td>\n",
       "      <td>22:26:31</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5268 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      Tweet Id        Username  \\\n",
       "1              1  1.340000e+18      Bulama8976   \n",
       "5              5  1.340000e+18       malaminuu   \n",
       "6              6  1.340000e+18        busuyikk   \n",
       "10            10  1.340000e+18  aesha_m_dawood   \n",
       "16            16  1.340000e+18    AbbanHajiya7   \n",
       "...          ...           ...             ...   \n",
       "4441        4445  1.340000e+18        MOyewola   \n",
       "8323        8327  1.330000e+18          nabrga   \n",
       "11372      11376  1.340000e+18       BonaNaija   \n",
       "9340        9344  1.340000e+18           Chude   \n",
       "7084        7088  1.340000e+18   _SecretSinner   \n",
       "\n",
       "                                                 Content  No of likes  \\\n",
       "1      HumilityEmpathyCourageVisionResilience and Acc...         13.0   \n",
       "5      The Statecritical policy priority is to build ...          5.0   \n",
       "6      AtikuSaraki and Kwankwanso may have been forgi...          0.0   \n",
       "10                                         Thank you üôèüèæüòä          0.0   \n",
       "16       Atiku Support Organization Aso   Aso to asorock          4.0   \n",
       "...                                                  ...          ...   \n",
       "4441   rydayI am a Muslim but I donbelieve in Hell fi...          0.0   \n",
       "8323   Bros u can go ahead n block me na ur phone n d...          2.0   \n",
       "11372  You must contest in 2023 presidential election...          2.0   \n",
       "9340   I said it when Funke did Your Excellencythat t...          3.0   \n",
       "7084                                 You do tho Jonathan          0.0   \n",
       "\n",
       "      No of Retweets No of Replies  No of quoteCount        Date      Time  \\\n",
       "1                  2             1               2.0  30/12/2020  23:51:09   \n",
       "5                  5             0               0.0  30/12/2020  23:43:47   \n",
       "6                  0             1               0.0  30/12/2020  23:40:53   \n",
       "10                 0             0               0.0  30/12/2020  23:35:47   \n",
       "16                 0             0               0.0  30/12/2020  23:18:55   \n",
       "...              ...           ...               ...         ...       ...   \n",
       "4441               0             0               0.0  30/12/2020  19:25:28   \n",
       "8323               0             0               0.0  22/11/2020  21:16:43   \n",
       "11372              1             0               0.0  30/12/2020   9:56:47   \n",
       "9340               0             0               0.0  30/12/2020  18:28:52   \n",
       "7084               0             1               0.0  30/12/2020  22:26:31   \n",
       "\n",
       "       Response  \n",
       "1      positive  \n",
       "5      positive  \n",
       "6      positive  \n",
       "10     positive  \n",
       "16     positive  \n",
       "...         ...  \n",
       "4441    neutral  \n",
       "8323    neutral  \n",
       "11372   neutral  \n",
       "9340    neutral  \n",
       "7084    neutral  \n",
       "\n",
       "[5268 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data['Response'] = tweet_data['Response'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = tweet_data[tweet_data['Response'] != 'neutral ']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response\n",
       "negative    2050\n",
       "neutral     2000\n",
       "positive    1218\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values\n",
    "tweet_data = tweet_data.dropna(subset=['Content', 'Response'])\n",
    "# Preprocess text data\n",
    "X = tweet_data['Content']\n",
    "y = tweet_data['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode response labels using label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "num_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = onehot_encoder.fit_transform(y_encoded.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(str)  # Convert elements to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and Padding\n",
    "max_sequence_length = 100\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(X, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open(r'glove.twitter.27B\\glove.twitter.27B.100d.txt', encoding='utf8') as f:  # Update with the path to your GloVe file\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding matrix\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_scores = {}\n",
    "for index, row in emoji_scores_data.iterrows():\n",
    "    emoji_scores[row['Emoji']] = {\n",
    "        'positive': row['Positive'],\n",
    "        'neutral': row['Neutral'],\n",
    "        'negative': row['Negative']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_emoji_scores_for_tweets(tweet_data, emoji_scores):\n",
    "    emoji_positive_scores_train = []\n",
    "\n",
    "    for tweet in tweet_data:\n",
    "        positive_scores = []  # List to store positive scores for each emoji in the tweet\n",
    "\n",
    "        emojis = re.findall(r'[^\\w\\s,]', tweet)  # Extract emojis from the tweet\n",
    "\n",
    "        for emoji_char in emojis:\n",
    "            if emoji_char in emoji_scores:\n",
    "                positive_score = emoji_scores[emoji_char]['positive']\n",
    "                positive_scores.append(positive_score)\n",
    "\n",
    "        # Calculate the average positive score for emojis in the tweet\n",
    "        avg_positive_score = sum(positive_scores) / len(positive_scores) if positive_scores else 0.0\n",
    "        emoji_positive_scores_train.append(avg_positive_score)\n",
    "\n",
    "    return emoji_positive_scores_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create model\n",
    "text_input = Input(shape=(max_sequence_length,))\n",
    "emoji_input = Input(shape=(1,))\n",
    "\n",
    "# Use emoji positive scores as input to the model\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length, weights=[embedding_matrix], trainable=False)(text_input)\n",
    "lstm_layer = Bidirectional(LSTM(units=64, dropout=0.2, recurrent_dropout=0.2))(embedding_layer)  # Reduced units\n",
    "merged_layer = Concatenate()([lstm_layer, emoji_input])\n",
    "\n",
    "output_layer = Dense(units=num_classes, activation='softmax', kernel_regularizer='l2')(merged_layer)  # Added L2 regularization\n",
    "model = Model(inputs=[text_input, emoji_input], outputs=output_layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation, and test sets while preserving class distribution\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y_onehot, test_size=0.1, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tweet texts from X_train sequences\n",
    "tweet_texts_train = tokenizer.sequences_to_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate emoji scores for training tweets\n",
    "emoji_positive_scores_train = calculate_emoji_scores_for_tweets(tweet_texts_train, emoji_scores)\n",
    "# Calculate emoji scores for validation tweets\n",
    "tweet_texts_val = tokenizer.sequences_to_texts(X_val)\n",
    "emoji_positive_scores_val = calculate_emoji_scores_for_tweets(tweet_texts_val, emoji_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate emoji scores for training and validation tweets\n",
    "emoji_positive_scores_train = calculate_emoji_scores_for_tweets(tweet_texts_train, emoji_scores)\n",
    "emoji_positive_scores_val = calculate_emoji_scores_for_tweets(tweet_texts_val, emoji_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks for early stopping\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "148/148 [==============================] - 12s 63ms/step - loss: 18.0013 - accuracy: 0.4253 - val_loss: 14.3145 - val_accuracy: 0.4388\n",
      "Epoch 2/10\n",
      "148/148 [==============================] - 9s 60ms/step - loss: 5.8691 - accuracy: 0.4812 - val_loss: 5.2440 - val_accuracy: 0.4641\n",
      "Epoch 3/10\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 1.6987 - accuracy: 0.5139 - val_loss: 1.2927 - val_accuracy: 0.4895\n",
      "Epoch 4/10\n",
      "148/148 [==============================] - 10s 66ms/step - loss: 1.0635 - accuracy: 0.5289 - val_loss: 1.1631 - val_accuracy: 0.5274\n",
      "Epoch 5/10\n",
      "148/148 [==============================] - 11s 73ms/step - loss: 1.0027 - accuracy: 0.5553 - val_loss: 1.0612 - val_accuracy: 0.5190\n",
      "Epoch 6/10\n",
      "148/148 [==============================] - 10s 68ms/step - loss: 1.0156 - accuracy: 0.5690 - val_loss: 0.9901 - val_accuracy: 0.5422\n",
      "Epoch 7/10\n",
      "148/148 [==============================] - 10s 70ms/step - loss: 0.9912 - accuracy: 0.5693 - val_loss: 1.0190 - val_accuracy: 0.5527\n",
      "Epoch 8/10\n",
      "148/148 [==============================] - 11s 74ms/step - loss: 0.9210 - accuracy: 0.5992 - val_loss: 0.9666 - val_accuracy: 0.5443\n",
      "Epoch 9/10\n",
      "148/148 [==============================] - 10s 71ms/step - loss: 0.9822 - accuracy: 0.6024 - val_loss: 1.0487 - val_accuracy: 0.5338\n",
      "Epoch 10/10\n",
      "148/148 [==============================] - 10s 71ms/step - loss: 0.9747 - accuracy: 0.6058 - val_loss: 0.9642 - val_accuracy: 0.5485\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit([np.array(X_train), np.array(emoji_positive_scores_train)], np.array(y_train),\n",
    "                    epochs=10, batch_size=32,\n",
    "                    validation_data=([np.array(X_val), np.array(emoji_positive_scores_val)], np.array(y_val)),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenizer using pickle\n",
    "with open('tokenizer.pkl', 'wb') as tokenizer_file:\n",
    "    pickle.dump(tokenizer, tokenizer_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained Keras model to an .h5 file\n",
    "model.save('bal_data_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the emoji scores using pickle\n",
    "with open('emoji_scores.pkl', 'wb') as emoji_scores_file:\n",
    "    pickle.dump(emoji_scores, emoji_scores_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
